{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Checking the data",
   "id": "161c7fdd6d1a0693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open (\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ],
   "id": "28b757fea4031e56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Using some simple example text, we can use the re.split command with the following syntax to split a text on whitespace characters:**",
   "id": "eaa4bcb3f266b5ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:20:49.644957Z",
     "start_time": "2025-02-04T21:20:49.641977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "text = \"Helo, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ],
   "id": "11199e7fbbd1f6d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Helo,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Let’s modify the regular expression splits on whitespaces (\\s), commas, and periods ([,.]):**",
   "id": "3168d52f27904d7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "print(result)"
   ],
   "id": "af4cc14ca98e3ec6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**We can see that the words and punctuation characters are now separate list entries just as we wanted:**\n",
    "\n",
    "**A small remaining problem is that the list still includes whitespace characters. Optionally, we can remove these redundant characters safely as follows:**"
   ],
   "id": "d6c6a9e7b51a8987"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:21:39.262067Z",
     "start_time": "2025-02-04T21:21:39.259134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ],
   "id": "9a97a7914a85f1b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Helo', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **The resulting whitespace-free output looks like as follows:**",
   "id": "3da8eca10da44a8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The tokenization scheme we devised here works well on the simple sample text. Let’s modify it a bit further so that it can also handle other types of punctuation, such as question marks, quotation marks, and the double-dashes we have seen earlier in the first 100 characters of Edith Wharton’s short story, along with additional special characters:**",
   "id": "7dae1a3400906975"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:22:55.468324Z",
     "start_time": "2025-02-04T21:22:55.464921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ],
   "id": "190198d73ac779f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Now that we have a basic tokenizer working, let’s apply it to Edith Wharton’s entire short story:**",
   "id": "53d07a40d65cdfc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:23:57.480928Z",
     "start_time": "2025-02-04T21:23:57.475950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ],
   "id": "c8fd7ae26fbc2de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**This print statement outputs 4690, which is the number of tokens in this text (without whitespaces). Let’s print the first 30 tokens for a quick visual check:**",
   "id": "dce631c6a99bbb96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:24:28.582582Z",
     "start_time": "2025-02-04T21:24:28.579581Z"
    }
   },
   "cell_type": "code",
   "source": "print(preprocessed[:30])",
   "id": "cdc9738147bda1e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting tokens into token IDs\n",
    "\n",
    "**let’s create a list of all unique tokens and sort them alphabetically to determine the vocabulary size:**"
   ],
   "id": "9e2dfd792ac183a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:27:23.002487Z",
     "start_time": "2025-02-04T21:27:22.997007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ],
   "id": "3887abf50942a81b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Now that we have seen that the vocabulary size is 1130. Let's print the first 51 entries for illustration purposes.**",
   "id": "5baf2460963a35d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:29:05.508067Z",
     "start_time": "2025-02-04T21:29:05.504366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i>= 50:\n",
    "        break"
   ],
   "id": "5415d5144c6c0656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Our next goal is to apply this vacabulary to convert new text into token IDs. And the reverse operation.**",
   "id": "49f66b4fc91dfa4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:40:04.936294Z",
     "start_time": "2025-02-04T21:40:04.932118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ],
   "id": "52da401dfd8a887b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:40:58.655440Z",
     "start_time": "2025-02-04T21:40:58.652471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "       Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ],
   "id": "4ed77b6af021ed0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:40:59.614824Z",
     "start_time": "2025-02-04T21:40:59.611750Z"
    }
   },
   "cell_type": "code",
   "source": "print(tokenizer.decode(ids))",
   "id": "6494168d80b51b4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**So far, so good. We implemented a tokenizer capable of tokenizing and detokenizing text based on a snippet from the training set. Let’s now apply it to a new text sample not contained in the training set:**",
   "id": "a738f7a8eabcc865"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:42:17.426925Z",
     "start_time": "2025-02-04T21:42:17.404149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Hello, do you like tea?\"\n",
    "print(tokenizer.encode(text))"
   ],
   "id": "365f7fe37a86d257",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHello, do you like tea?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[15], line 9\u001B[0m, in \u001B[0;36mSimpleTokenizerV1.encode\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m      7\u001B[0m preprocessed \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m([,.?_!\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m()\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m]|--|\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms)\u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[1;32m      8\u001B[0m preprocessed \u001B[38;5;241m=\u001B[39m [item\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m preprocessed \u001B[38;5;28;01mif\u001B[39;00m item\u001B[38;5;241m.\u001B[39mstrip()]\n\u001B[0;32m----> 9\u001B[0m ids \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstr_to_int[s] \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m preprocessed]\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ids\n",
      "Cell \u001B[0;32mIn[15], line 9\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      7\u001B[0m preprocessed \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m([,.?_!\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m()\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m]|--|\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms)\u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[1;32m      8\u001B[0m preprocessed \u001B[38;5;241m=\u001B[39m [item\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m preprocessed \u001B[38;5;28;01mif\u001B[39;00m item\u001B[38;5;241m.\u001B[39mstrip()]\n\u001B[0;32m----> 9\u001B[0m ids \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstr_to_int\u001B[49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m preprocessed]\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ids\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Hello'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The problem is that the word “Hello” was not used in the “The Verdict” short story. Hence, it is not contained in the vocabulary. This highlights the need to consider large and diverse training sets to extend the vocabulary when working on LLMs.**",
   "id": "cd663f70c217be74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**We will modify the vocabulary and tokenizer, SimpleTokenizerV2, to support two new tokens, <|unk|> and <|endoftext|>**",
   "id": "168b45addcf7652c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:45:20.445155Z",
     "start_time": "2025-02-04T21:45:20.439897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "\n",
    "print(len(vocab.items()))"
   ],
   "id": "3bcdf20d1e74dbff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:45:40.180856Z",
     "start_time": "2025-02-04T21:45:40.178576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ],
   "id": "334dbb8705306a5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:49:35.997154Z",
     "start_time": "2025-02-04T21:49:35.990788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleTokenizerV2:\n",
    "    # A simple text tokenizer that handles unknown words\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ],
   "id": "5523d7e4734ec390",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:50:13.231365Z",
     "start_time": "2025-02-04T21:50:13.229009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ],
   "id": "f1ef1afae2cb90cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:51:11.227744Z",
     "start_time": "2025-02-04T21:51:11.225335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))"
   ],
   "id": "13924edd56442e55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T21:52:13.617300Z",
     "start_time": "2025-02-04T21:52:13.615010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = tokenizer.encode(text)\n",
    "print(tokenizer.decode(ids))"
   ],
   "id": "511feb9b9fa08bdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**GPT models use a byte pair encoding tokenizer**",
   "id": "310b120da791eb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Byte Pair Encoding",
   "id": "23ac839c2c4da02b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:08:59.275034Z",
     "start_time": "2025-02-04T22:08:56.044913Z"
    }
   },
   "cell_type": "code",
   "source": "pip install tiktoken",
   "id": "dfaf91f2a5358ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting tiktoken\r\n",
      "  Downloading tiktoken-0.8.0-cp39-cp39-macosx_11_0_arm64.whl (983 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 983 kB 1.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.26.0 in /Users/hulkiciray/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2.32.3)\r\n",
      "Collecting regex>=2022.1.18\r\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 284 kB 2.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/hulkiciray/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hulkiciray/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hulkiciray/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hulkiciray/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\r\n",
      "Installing collected packages: regex, tiktoken\r\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.8.0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 25.0 is available.\r\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:12:07.003743Z",
     "start_time": "2025-02-04T22:12:06.977489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ],
   "id": "abf61ea5ea645185",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Once installed, we can instantiate the BPE tokenizer from tiktoken as follows:**",
   "id": "79955af53df52e58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:12:43.319601Z",
     "start_time": "2025-02-04T22:12:39.949539Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = tiktoken.get_encoding(\"gpt2\")",
   "id": "3390a39fe6799669",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hulkiciray/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:14:53.857342Z",
     "start_time": "2025-02-04T22:14:53.854431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ],
   "id": "ca0a3f493089bb15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:15:46.104196Z",
     "start_time": "2025-02-04T22:15:46.100115Z"
    }
   },
   "cell_type": "code",
   "source": "print(tokenizer.decode(integers))",
   "id": "3755bd8166b214a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "tiktoken's BPE tokenizer handles the unknown words by itself.\n",
    "\n",
    "**The next step is creating the embeddings for the LLM is to generate the input-target paris required for training an LLM.**"
   ],
   "id": "69d5302e53833edb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:41:39.603543Z",
     "start_time": "2025-02-05T20:41:39.587607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ],
   "id": "a0a854a0d8a9558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Next, we remove the first 50 tokens from the dataset for demonstration purposes, as it results in a slightly more interesting text passage in the next steps:**",
   "id": "5d6d6da7c6ce5f86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:47:52.759690Z",
     "start_time": "2025-02-05T20:47:52.753820Z"
    }
   },
   "cell_type": "code",
   "source": "enc_sample = enc_text[50:]",
   "id": "5af460cf30f297c6",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:49:52.288190Z",
     "start_time": "2025-02-05T20:49:52.286091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ],
   "id": "d9d9e90c7581ea1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:51:17.655737Z",
     "start_time": "2025-02-05T20:51:17.652565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ],
   "id": "acdf8113bfe0d8aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Everything left of the arrow (---->) refers to the input an LLM would receive, and the token ID on the right side of the arrow represents the target token ID that the LLM is supposed to predict. Let’s repeat the previous code but convert the token IDs into text:**",
   "id": "152b6f33a6db9d78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:52:48.796522Z",
     "start_time": "2025-02-05T20:52:48.792709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "id": "c54d9301a9bc3976",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**We now created the input-target pairs to use for LLM training.**\n",
    "\n",
    "There is only 1 more task before we can turn the tokens into embeddings: implementing and efficient **data loader** that iterated over the input **dataset** and returns the inputs and targets as **pytorch tensors**, which can be thought of as multidimensional arrays.\n",
    "\n",
    "In particular, we are interested in returning **2** tensors: an input tensor containing the text that the **LLM sees** and a target tensor that includes the targets for the **LLM to predict**."
   ],
   "id": "661cfb6948e1a01d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T21:09:52.910765Z",
     "start_time": "2025-02-05T21:09:52.899660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids)-max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ],
   "id": "9dca8756539dafb5",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T21:06:19.253800Z",
     "start_time": "2025-02-05T21:06:14.939671Z"
    }
   },
   "cell_type": "code",
   "source": "pip install numpy",
   "id": "977d7b52f2e59b85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting numpy\r\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\r\n",
      "Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.3/5.3 MB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: numpy\r\n",
      "\u001B[33m  WARNING: The scripts f2py and numpy-config are installed in '/Users/hulkiciray/Library/Python/3.9/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\r\n",
      "\u001B[0mSuccessfully installed numpy-2.0.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The following code uses the GPTDatasetV1 to load the inputs in batches via a PyTorch DataLoader.**",
   "id": "cc55fd91e7943def"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T21:15:00.692751Z",
     "start_time": "2025-02-05T21:15:00.688277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length=max_length, stride=stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ],
   "id": "8da9495d74bc5c5e",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T21:19:31.750243Z",
     "start_time": "2025-02-05T21:19:31.719972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=4, max_length=4, stride=1, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "\n",
    "print(first_batch)"
   ],
   "id": "35836899f0d0afa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464],\n",
      "        [ 367, 2885, 1464, 1807],\n",
      "        [2885, 1464, 1807, 3619],\n",
      "        [1464, 1807, 3619,  402]]), tensor([[ 367, 2885, 1464, 1807],\n",
      "        [2885, 1464, 1807, 3619],\n",
      "        [1464, 1807, 3619,  402],\n",
      "        [1807, 3619,  402,  271]])]\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**The first_batch variable contains two tensors: the first tensor stores the input token IDs, and the second tensor stores the target token IDs. Since the max_length is set to 4, each of the two tensors contains four tokens IDs.**\n",
    "\n",
    "Let's look briefly at how we can use the data loader to sample with a batch size greater than 1:"
   ],
   "id": "8ed5128e009dd85a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T21:28:12.785472Z",
     "start_time": "2025-02-05T21:28:12.775808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"Outputs:\\n\", targets)"
   ],
   "id": "56a69e66d8208724",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Outputs:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Not that we increase the stride to 4 to utilize the dataset fully. This avoids any overlap between the batches sice more overlap could lead to increased overfitting.**\n",
    "\n",
    "## Creating Token Embeddings"
   ],
   "id": "db23edd5a4bedcd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T22:40:41.135886Z",
     "start_time": "2025-02-05T22:40:41.080748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ],
   "id": "53b8ab6eae1cebd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here you may see that the height of the matrix represents the vocab_size, width of the matrix represents the embedding_dim.\n",
    "\n",
    "Another explanation is you can see that the weight matrix has six rows and three columns. There is one row for each of the six possible tokens in the vocabulary, and there is one column for each of the three embedding dimensions.\n",
    "\n",
    "Now let's apply it to a token ID to obtain the embedding vector."
   ],
   "id": "c0f0c4c0b73fa667"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T22:43:39.170355Z",
     "start_time": "2025-02-05T22:43:39.159910Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_layer(torch.tensor([3])))",
   "id": "7782e416c672e726",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If we compare the embedding vector for token ID 3 to the previous embedding matrix, we see that it is identical to the fourth row. In other words, the embedding layer is essentially a lookup operation that retrieves rows from the embedding layer's weight matrix via token ID.\n",
    "\n",
    "We’ve seen how to convert a single token ID into a three-dimensional embedding vector. Let’s now apply that to all four input IDs **(torch.tensor([2, 3, 5, 1])):**"
   ],
   "id": "460c1a0e0ccb8dfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T22:51:07.661162Z",
     "start_time": "2025-02-05T22:51:07.653467Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_layer(input_ids))",
   "id": "16bfb924b5710655",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Having now created embedding vectors from token IDs, next we’ll add a small modification to these embedding vectors to encode positional information about a token within a text.\n",
    "\n",
    "## Encoding Word Positions"
   ],
   "id": "530e105252dc27f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:06:23.476225Z",
     "start_time": "2025-02-05T23:06:23.361063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ],
   "id": "92ad52eb1e619008",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:07:51.943749Z",
     "start_time": "2025-02-05T23:07:51.926517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ],
   "id": "fb6d6d2255492388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can see, the token ID tensor is 8 × 4 dimensional, meaning that the data batch consists of **eight text samples** with **four tokens each**.\n",
    "\n",
    "Let’s now use the embedding layer to embed these token IDs into 256-dimensional vectors:"
   ],
   "id": "f3e2d0b2fb9fc656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:09:16.319127Z",
     "start_time": "2025-02-05T23:09:16.316120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ],
   "id": "3406e08ac2183537",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The 8 × 4 × 256–dimensional tensor output shows that each token ID is now embedded as a 256-dimensional vector.",
   "id": "9495de1da72184c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:43:05.196231Z",
     "start_time": "2025-02-05T23:43:05.187297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ],
   "id": "35cd1866d52446a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see, the positional embedding tensor consists of four 256-dimensional vectors. We can now add these directly to the token embeddings, where PyTorch will add the 4 × 256–dimensional pos_embeddings tensor to each 4 × 256–dimensional token embedding tensor in each of the eight batches:",
   "id": "d1c70728d6f9f6f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:44:07.894996Z",
     "start_time": "2025-02-05T23:44:07.890684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ],
   "id": "660f48c163e81d15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "- LLMs require textual data to be converted into numerical vectors, known as embeddings, since they can’t process raw text. Embeddings transform discrete data (like words or images) into continuous vector spaces, making them compatible with neural network operations.\n",
    "- As the first step, raw text is broken into tokens, which can be words or characters. Then, the tokens are converted into integer representations, termed token IDs.\n",
    "- Special tokens, such as <|unk|> and <|endoftext|>, can be added to enhance the model’s understanding and handle various contexts, such as unknown words or marking the boundary between unrelated texts.\n",
    "- The byte pair encoding (BPE) tokenizer used for LLMs like GPT-2 and GPT-3 can efficiently handle unknown words by breaking them down into subword units or individual characters.\n",
    "- We use a sliding window approach on tokenized data to generate input–target pairs for LLM training.\n",
    "- Embedding layers in PyTorch function as a lookup operation, retrieving vectors corresponding to token IDs. The resulting embedding vectors provide continuous representations of tokens, which is crucial for training deep learning models like LLMs.\n",
    "- While token embeddings provide consistent vector representations for each token, they lack a sense of the token’s position in a sequence. To rectify this, two main types of positional embeddings exist: absolute and relative. OpenAI’s GPT models utilize absolute positional embeddings, which are added to the token embedding vectors and are optimized during the model training."
   ],
   "id": "dc58bab116af6306"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
