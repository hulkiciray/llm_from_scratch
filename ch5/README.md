# Chapter 5: Pretraining on Unlabeled Data

This chapter we will dive deeper into the training phase of LLMs. The topics we are going to cover are as follow;

- Evaluating generative text models
  - Using GPT to generate text
  - Calculating the text generation loss
  - Calculating the training and validation set losses
- Training an LLM
- Decoding strategies to control rendomness
  - Temperature scaling
  - Top-k sampling
  - Modifying the text generation function
- Loading and saving model weights in PyTorch
- Loading pretrained weights from OpenAI

### Summary of the Chapter
- ...
- ...